{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors</th>\n",
       "      <th>critics_score</th>\n",
       "      <th>date</th>\n",
       "      <th>directors</th>\n",
       "      <th>editor</th>\n",
       "      <th>genre</th>\n",
       "      <th>langage</th>\n",
       "      <th>length</th>\n",
       "      <th>nationality</th>\n",
       "      <th>viewers_score</th>\n",
       "      <th>us_first_week_boxoffice</th>\n",
       "      <th>french_first_week_boxoffice</th>\n",
       "      <th>french_visa</th>\n",
       "      <th>title</th>\n",
       "      <th>vo_title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Arieh Worthalter, Arthur Harari, Stéphan Guér...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>[Cédric Kahn]</td>\n",
       "      <td>Ad Vitam</td>\n",
       "      <td>[Policier, Drame, Historique, Judiciaire]</td>\n",
       "      <td>[Français]</td>\n",
       "      <td>116.0</td>\n",
       "      <td>[France]</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110011.0</td>\n",
       "      <td>157303</td>\n",
       "      <td>Le Procès Goldman</td>\n",
       "      <td>None</td>\n",
       "      <td>/article/fichearticle_gen_carticle=1000093547....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Monica Bellucci, Vincent Cassel, Albert Dupon...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>[Gaspar Noé]</td>\n",
       "      <td>Carlotta Films</td>\n",
       "      <td>[Drame, Thriller]</td>\n",
       "      <td>[Anglais, Français, Italien, Espagnol]</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[France]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2905.0</td>\n",
       "      <td>153336</td>\n",
       "      <td>Irréversible - Inversion Intégrale</td>\n",
       "      <td>None</td>\n",
       "      <td>/article/fichearticle_gen_carticle=18692477.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Thom Hoffman]</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>[Richard Claus, Karsten Kiilerich]</td>\n",
       "      <td>Le Pacte</td>\n",
       "      <td>[Aventure, Animation, Comédie, Famille]</td>\n",
       "      <td>[Néerlandais]</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[Danemark, France, Allemagne, Pays-Bas]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39119.0</td>\n",
       "      <td>160622</td>\n",
       "      <td>Petit Panda en Afrique</td>\n",
       "      <td>Panda Bear in Africa</td>\n",
       "      <td>/article/fichearticle_gen_carticle=1000096064....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Lou de Laâge, Raphaël Personnaz, Isabelle Car...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>[Olivier Treiner]</td>\n",
       "      <td>SND</td>\n",
       "      <td>[Drame]</td>\n",
       "      <td>[Français]</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[France]</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64039.0</td>\n",
       "      <td>152607</td>\n",
       "      <td>Le Tourbillon de la vie</td>\n",
       "      <td>None</td>\n",
       "      <td>/article/fichearticle_gen_carticle=1000006465....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Michael B. Jordan, Jamie Foxx, Brie Larson, R...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>[Destin Daniel Cretton]</td>\n",
       "      <td>Warner Bros. France</td>\n",
       "      <td>[Biopic, Drame]</td>\n",
       "      <td>[Anglais]</td>\n",
       "      <td>137.0</td>\n",
       "      <td>[U.S.A.]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9713228.0</td>\n",
       "      <td>113153.0</td>\n",
       "      <td>152118</td>\n",
       "      <td>La Voie de la justice</td>\n",
       "      <td>Just Mercy</td>\n",
       "      <td>/video/player_gen_cmedia=19586793&amp;cfilm=239735...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              actors  critics_score  \\\n",
       "0  [Arieh Worthalter, Arthur Harari, Stéphan Guér...            4.4   \n",
       "1  [Monica Bellucci, Vincent Cassel, Albert Dupon...            3.5   \n",
       "2                                     [Thom Hoffman]            2.8   \n",
       "3  [Lou de Laâge, Raphaël Personnaz, Isabelle Car...            3.3   \n",
       "4  [Michael B. Jordan, Jamie Foxx, Brie Larson, R...            3.0   \n",
       "\n",
       "        date                           directors               editor  \\\n",
       "0 2023-09-27                       [Cédric Kahn]             Ad Vitam   \n",
       "1 2020-08-26                        [Gaspar Noé]       Carlotta Films   \n",
       "2 2024-08-07  [Richard Claus, Karsten Kiilerich]             Le Pacte   \n",
       "3 2022-12-21                   [Olivier Treiner]                  SND   \n",
       "4 2020-01-29             [Destin Daniel Cretton]  Warner Bros. France   \n",
       "\n",
       "                                       genre  \\\n",
       "0  [Policier, Drame, Historique, Judiciaire]   \n",
       "1                          [Drame, Thriller]   \n",
       "2    [Aventure, Animation, Comédie, Famille]   \n",
       "3                                    [Drame]   \n",
       "4                            [Biopic, Drame]   \n",
       "\n",
       "                                  langage  length  \\\n",
       "0                              [Français]   116.0   \n",
       "1  [Anglais, Français, Italien, Espagnol]    90.0   \n",
       "2                           [Néerlandais]    84.0   \n",
       "3                              [Français]   120.0   \n",
       "4                               [Anglais]   137.0   \n",
       "\n",
       "                               nationality  viewers_score  \\\n",
       "0                                 [France]            3.9   \n",
       "1                                 [France]            NaN   \n",
       "2  [Danemark, France, Allemagne, Pays-Bas]            3.0   \n",
       "3                                 [France]            3.8   \n",
       "4                                 [U.S.A.]            4.1   \n",
       "\n",
       "   us_first_week_boxoffice  french_first_week_boxoffice french_visa  \\\n",
       "0                      0.0                     110011.0      157303   \n",
       "1                      0.0                       2905.0      153336   \n",
       "2                      0.0                      39119.0      160622   \n",
       "3                      0.0                      64039.0      152607   \n",
       "4                9713228.0                     113153.0      152118   \n",
       "\n",
       "                                title              vo_title  \\\n",
       "0                   Le Procès Goldman                  None   \n",
       "1  Irréversible - Inversion Intégrale                  None   \n",
       "2              Petit Panda en Afrique  Panda Bear in Africa   \n",
       "3             Le Tourbillon de la vie                  None   \n",
       "4               La Voie de la justice            Just Mercy   \n",
       "\n",
       "                                                 url  \n",
       "0  /article/fichearticle_gen_carticle=1000093547....  \n",
       "1   /article/fichearticle_gen_carticle=18692477.html  \n",
       "2  /article/fichearticle_gen_carticle=1000096064....  \n",
       "3  /article/fichearticle_gen_carticle=1000006465....  \n",
       "4  /video/player_gen_cmedia=19586793&cfilm=239735...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"gros_data.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>box_office</th>\n",
       "      <th>is_prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-01-01</th>\n",
       "      <td>9.822903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-02-01</th>\n",
       "      <td>11.884946</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-01</th>\n",
       "      <td>11.417790</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-04-01</th>\n",
       "      <td>10.506531</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-05-01</th>\n",
       "      <td>9.071718</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            box_office  is_prediction\n",
       "month                                \n",
       "1989-01-01    9.822903            1.0\n",
       "1989-02-01   11.884946            1.0\n",
       "1989-03-01   11.417790            1.0\n",
       "1989-04-01   10.506531            1.0\n",
       "1989-05-01    9.071718            1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_afluence_filled = pd.read_parquet(\"affluence_docker.parquet\")\n",
    "df_afluence_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>box_office</th>\n",
       "      <th>is_prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-01-01</th>\n",
       "      <td>9.822903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-02-01</th>\n",
       "      <td>11.884946</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-01</th>\n",
       "      <td>11.417790</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-04-01</th>\n",
       "      <td>10.506531</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-05-01</th>\n",
       "      <td>9.071718</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            box_office  is_prediction\n",
       "month                                \n",
       "1989-01-01    9.822903            1.0\n",
       "1989-02-01   11.884946            1.0\n",
       "1989-03-01   11.417790            1.0\n",
       "1989-04-01   10.506531            1.0\n",
       "1989-05-01    9.071718            1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actors = pd.read_parquet(\"affluence_docker.parquet\")\n",
    "df_actors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_national_affluence(x, filled = False):\n",
    "    date = pd.to_datetime(f\"{x.year}-{x.month:02d}-01\")\n",
    "    if filled:\n",
    "        return df_afluence_filled.loc[date, 'box_office'] if date in df_afluence_filled.index else None\n",
    "    else:\n",
    "        return df_afluence.loc[date, 'box_office'] if date in df_afluence.index else None\n",
    "    \n",
    "def score_actors(x, method=\"boxoffice_average\"):\n",
    "    max_score = 0\n",
    "    scores = []\n",
    "    sum_score = 0\n",
    "    for actor in x:\n",
    "        if actor.replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").strip().lower() in df_actors.index :\n",
    "            max_score = max(max_score, df_actors.loc[actor.replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").strip().lower(), method])\n",
    "            scores.append(df_actors.loc[actor.replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").strip().lower(), method])\n",
    "            sum_score += df_actors.loc[actor.replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").strip().lower(), method]\n",
    "    if len(scores) == 0:\n",
    "        mean_scores = 0\n",
    "    else:\n",
    "        mean_scores = np.mean(scores)\n",
    "    return {\"max_score\":max_score, \"mean_scores\":mean_scores, \"sum_score\":sum_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['genre', 'langage', 'nationality', 'actors']:\n",
    "    df[col] = df[col].mask(df[col].isna(), ['no value'])\n",
    "df['national_affluence'] = df['date'].apply(lambda x : put_national_affluence(x,True))\n",
    "actor_scores = df['actors'].apply(lambda x : score_actors(x)) \n",
    "df['french_prod'] = df['nationality'].apply(lambda x: 1 if \"France\" in x else 0)\n",
    "df['usa_prod'] = df['nationality'].apply(lambda x: 1 if \"U.S.A.\" in x else 0)\n",
    "df['french_langage'] = df['langage'].apply(lambda x: 1 if \"Français\" in x else 0)\n",
    "df['english_langage'] = df['langage'].apply(lambda x: 1 if \"Anglais\" in x else 0)\n",
    "df['number_actors'] = df['actors'].apply(lambda x: len(x))\n",
    "df['max_average_actor'] = actor_scores.apply(lambda x : x[\"max_score\"])\n",
    "df['sum_score_actor'] = actor_scores.apply(lambda x : x[\"sum_score\"])\n",
    "df['mean_average_actor'] = actor_scores.apply(lambda x : x[\"mean_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['actors', 'critics_score', 'date', 'directors', 'editor', 'genre',\n",
       "       'langage', 'length', 'nationality', 'viewers_score',\n",
       "       'us_first_week_boxoffice', 'french_first_week_boxoffice', 'french_visa',\n",
       "       'title', 'vo_title', 'url', 'national_affluence', 'french_prod',\n",
       "       'usa_prod', 'french_langage', 'english_langage', 'number_actors',\n",
       "       'max_average_actor', 'sum_score_actor', 'mean_average_actor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actors                                 object\n",
       "critics_score                         float64\n",
       "date                           datetime64[ns]\n",
       "directors                              object\n",
       "editor                                 object\n",
       "genre                                  object\n",
       "langage                                object\n",
       "length                                float64\n",
       "nationality                            object\n",
       "viewers_score                         float64\n",
       "us_first_week_boxoffice               float64\n",
       "french_first_week_boxoffice           float64\n",
       "french_visa                            object\n",
       "title                                  object\n",
       "vo_title                               object\n",
       "url                                    object\n",
       "national_affluence                    float64\n",
       "french_prod                             int64\n",
       "usa_prod                                int64\n",
       "french_langage                          int64\n",
       "english_langage                         int64\n",
       "number_actors                           int64\n",
       "max_average_actor                       int64\n",
       "sum_score_actor                         int64\n",
       "mean_average_actor                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_average_actor\n",
       "False    9151\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"max_average_actor\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       189607.906250\n",
      "1            0.000000\n",
      "2       537705.826464\n",
      "3            0.000000\n",
      "4            0.000000\n",
      "            ...      \n",
      "9153         0.000000\n",
      "9154         0.000000\n",
      "9155         0.000000\n",
      "9156         0.000000\n",
      "9157         0.000000\n",
      "Name: genre_third_target_transform, Length: 9151, dtype: float64\n",
      "0       420527.528184\n",
      "1       381754.506923\n",
      "2       729750.547043\n",
      "3       141083.341007\n",
      "4       211960.965418\n",
      "            ...      \n",
      "9153    792219.491342\n",
      "9154    381754.506923\n",
      "9155    614841.678750\n",
      "9156    381754.506923\n",
      "9157    141083.341007\n",
      "Name: genre_first_target_transform, Length: 9151, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for col in ['genre', 'langage', 'directors', 'nationality']:\n",
    "    col_res = []\n",
    "    col_boxoffice_means = {}\n",
    "    for col_list in df[col]:\n",
    "        col_res.extend(col_list)\n",
    "    unique_col = list(set(col_res))\n",
    "    for item in unique_col:\n",
    "        df_mask = df[df[col].apply(lambda x : item in x )]\n",
    "        mean_value = df_mask['french_first_week_boxoffice'].mean()\n",
    "        col_boxoffice_means[item] = mean_value\n",
    "    df[f\"{col}_target_transform\"] = df[col].apply(lambda x : [col_boxoffice_means[s] for s in x])\n",
    "    df[f\"{col}_target_transform\"] = df[f\"{col}_target_transform\"].apply(lambda x : sorted(x,reverse=True))\n",
    "    df[f\"{col}_first_target_transform\"] = df[f\"{col}_target_transform\"].apply(lambda x : x[0] if len(x)>0 else 0)\n",
    "    df[f\"{col}_second_target_transform\"] = df[f\"{col}_target_transform\"].apply(lambda x : x[1] if len(x)>1 else 0)\n",
    "    df[f\"{col}_third_target_transform\"] = df[f\"{col}_target_transform\"].apply(lambda x : x[2] if len(x)>2 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9151, 5950)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycaret.regression as pcr\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Ajout des nouvelles features\n",
    "# df['month'] = df['date'].dt.month\n",
    "# df['day_of_week'] = df['date'].dt.dayofweek\n",
    "# df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "\n",
    "# One-hot encoding pour les list\n",
    "for col in ['genre', 'langage', 'directors', 'nationality']:\n",
    "    col_res = []\n",
    "    for col_list in df[col]:\n",
    "        col_res.extend(col_list)\n",
    "    unique_col = list(set(col_res))\n",
    "\n",
    "    for truc in unique_col:\n",
    "        df[f'{col}_{truc}'] = df[col].apply(lambda x: 1 if truc in x else 0)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_split(df, test_years=3, test_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Crée un découpage train/test basé sur le temps.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame avec les données\n",
    "        test_years: Nombre d'années récentes à considérer pour le découpage\n",
    "        test_ratio: Proportion des films des années récentes à mettre dans le test set\n",
    "    \n",
    "    Returns:\n",
    "        indices_train, indices_test\n",
    "    \"\"\"\n",
    "    # Convertir en datetime si ce n'est pas déjà fait\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    # Déterminer la date limite pour les dernières années\n",
    "    max_date = df[\"date\"].max()\n",
    "    cutoff_date = pd.Timestamp(year=max_date.year - test_years, month=1, day=1)\n",
    "    \n",
    "    # Créer un masque pour les films récents\n",
    "    recent_mask = df[\"date\"] >= cutoff_date\n",
    "    \n",
    "    # Séparer les indices en entrainement et test\n",
    "    old_indices = df[~recent_mask].index.tolist()\n",
    "    recent_indices = df[recent_mask].index.tolist()\n",
    "    \n",
    "    # Trier les indices récents par date pour pouvoir prendre un film sur deux\n",
    "    recent_sorted = sorted([(idx, df.loc[idx, \"date\"]) for idx in recent_indices], \n",
    "                           key=lambda x: x[1])\n",
    "    recent_indices_sorted = [item[0] for item in recent_sorted]\n",
    "    \n",
    "    # Prendre un film sur deux dans les données récentes pour le test\n",
    "    test_size = int(len(recent_indices_sorted) * test_ratio)\n",
    "    \n",
    "    # Option 1: Prendre aléatoirement test_ratio des films récents\n",
    "    np.random.seed(42)\n",
    "    test_indices = np.random.choice(recent_indices_sorted, size=test_size, replace=False)\n",
    "    \n",
    "    # Option 2: Prendre un film sur deux chronologiquement\n",
    "    # test_indices = recent_indices_sorted[::int(1/test_ratio)] if test_ratio <= 0.5 else recent_indices_sorted\n",
    "\n",
    "    train_indices = [idx for idx in df.index if idx not in test_indices]\n",
    "    \n",
    "    print(f\"Découpage temporel: {len(train_indices)} films pour l'entrainement, {len(test_indices)} films pour le test\")\n",
    "    # print(f\"Plage de dates d'entrainement: {df.loc[train_indices, \"date\"].min()} à {df.loc[train_indices, \"date\"].max()}\")\n",
    "    # print(f\"Plage de dates de test: {df.loc[test_indices, \"date\"].min()} à {df.loc[test_indices, \"date\"].max()}\")\n",
    "    \n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Découpage temporel: 8694 films pour l'entrainement, 457 films pour le test\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['critics_score', 'viewers_score', 'us_first_week_boxoffice', \n",
    "                   'french_visa', 'title', 'vo_title', 'url', 'genre', 'directors', 'langage', 'nationality', 'actors']\n",
    "\n",
    "train_indices, test_indices = time_based_split(df, test_years=3, test_ratio=0.3)\n",
    "train = df.loc[train_indices]\n",
    "test = df.loc[train_indices]\n",
    "\n",
    "# df = df.sort_values(by='date')\n",
    "# split_date = df['date'].iloc[int(len(df) * 0.8)]  # 80% train, 20% test\n",
    "# train = df[df['date'] < split_date]\n",
    "# test = df[df['date'] >= split_date]\n",
    "train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "test.drop(columns_to_drop, axis=1, inplace=True)\n",
    "train['transformed_target'] = np.log1p(train['french_first_week_boxoffice'])\n",
    "test['transformed_target'] = np.log1p(test['french_first_week_boxoffice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd04e_row11_col1, #T_fd04e_row17_col1, #T_fd04e_row19_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd04e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd04e_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_fd04e_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fd04e_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_fd04e_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fd04e_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_fd04e_row1_col1\" class=\"data row1 col1\" >transformed_target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fd04e_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_fd04e_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fd04e_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_fd04e_row3_col1\" class=\"data row3 col1\" >(8694, 5939)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fd04e_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_fd04e_row4_col1\" class=\"data row4 col1\" >(8694, 5941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fd04e_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_fd04e_row5_col1\" class=\"data row5 col1\" >(6085, 5941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_fd04e_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_fd04e_row6_col1\" class=\"data row6 col1\" >(2609, 5941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_fd04e_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_fd04e_row7_col1\" class=\"data row7 col1\" >5936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_fd04e_row8_col0\" class=\"data row8 col0\" >Date features</td>\n",
       "      <td id=\"T_fd04e_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_fd04e_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_fd04e_row9_col1\" class=\"data row9 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_fd04e_row10_col0\" class=\"data row10 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_fd04e_row10_col1\" class=\"data row10 col1\" >0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_fd04e_row11_col0\" class=\"data row11 col0\" >Preprocess</td>\n",
       "      <td id=\"T_fd04e_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_fd04e_row12_col0\" class=\"data row12 col0\" >Imputation type</td>\n",
       "      <td id=\"T_fd04e_row12_col1\" class=\"data row12 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_fd04e_row13_col0\" class=\"data row13 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_fd04e_row13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_fd04e_row14_col0\" class=\"data row14 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_fd04e_row14_col1\" class=\"data row14 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_fd04e_row15_col0\" class=\"data row15 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_fd04e_row15_col1\" class=\"data row15 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_fd04e_row16_col0\" class=\"data row16 col0\" >Encoding method</td>\n",
       "      <td id=\"T_fd04e_row16_col1\" class=\"data row16 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_fd04e_row17_col0\" class=\"data row17 col0\" >Transformation</td>\n",
       "      <td id=\"T_fd04e_row17_col1\" class=\"data row17 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_fd04e_row18_col0\" class=\"data row18 col0\" >Transformation method</td>\n",
       "      <td id=\"T_fd04e_row18_col1\" class=\"data row18 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_fd04e_row19_col0\" class=\"data row19 col0\" >Normalize</td>\n",
       "      <td id=\"T_fd04e_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_fd04e_row20_col0\" class=\"data row20 col0\" >Normalize method</td>\n",
       "      <td id=\"T_fd04e_row20_col1\" class=\"data row20 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_fd04e_row21_col0\" class=\"data row21 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_fd04e_row21_col1\" class=\"data row21 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_fd04e_row22_col0\" class=\"data row22 col0\" >Fold Number</td>\n",
       "      <td id=\"T_fd04e_row22_col1\" class=\"data row22 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_fd04e_row23_col0\" class=\"data row23 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_fd04e_row23_col1\" class=\"data row23 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_fd04e_row24_col0\" class=\"data row24 col0\" >Use GPU</td>\n",
       "      <td id=\"T_fd04e_row24_col1\" class=\"data row24 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_fd04e_row25_col0\" class=\"data row25 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_fd04e_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_fd04e_row26_col0\" class=\"data row26 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_fd04e_row26_col1\" class=\"data row26 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd04e_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_fd04e_row27_col0\" class=\"data row27 col0\" >USI</td>\n",
       "      <td id=\"T_fd04e_row27_col1\" class=\"data row27 col1\" >b2f7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x73c2732bce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>11:04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Ridge Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                \n",
       "                                                                \n",
       "Initiated  . . . . . . . . . . . . . . . . . .          11:04:18\n",
       "Status     . . . . . . . . . . . . . . . . . .  Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Ridge Regression"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de4df th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_de4df_row0_col0, #T_de4df_row0_col1, #T_de4df_row0_col2, #T_de4df_row0_col3, #T_de4df_row0_col4, #T_de4df_row0_col5, #T_de4df_row0_col6, #T_de4df_row0_col7, #T_de4df_row1_col0, #T_de4df_row1_col1, #T_de4df_row1_col2, #T_de4df_row1_col3, #T_de4df_row1_col4, #T_de4df_row1_col5, #T_de4df_row1_col6, #T_de4df_row1_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de4df\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_de4df_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_de4df_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_de4df_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_de4df_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_de4df_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_de4df_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_de4df_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_de4df_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de4df_level0_row0\" class=\"row_heading level0 row0\" >lasso</th>\n",
       "      <td id=\"T_de4df_row0_col0\" class=\"data row0 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_de4df_row0_col1\" class=\"data row0 col1\" >0.8210</td>\n",
       "      <td id=\"T_de4df_row0_col2\" class=\"data row0 col2\" >1.0939</td>\n",
       "      <td id=\"T_de4df_row0_col3\" class=\"data row0 col3\" >1.0451</td>\n",
       "      <td id=\"T_de4df_row0_col4\" class=\"data row0 col4\" >0.8261</td>\n",
       "      <td id=\"T_de4df_row0_col5\" class=\"data row0 col5\" >0.1268</td>\n",
       "      <td id=\"T_de4df_row0_col6\" class=\"data row0 col6\" >0.1036</td>\n",
       "      <td id=\"T_de4df_row0_col7\" class=\"data row0 col7\" >11.1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de4df_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_de4df_row1_col0\" class=\"data row1 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_de4df_row1_col1\" class=\"data row1 col1\" >2661925779000.2485</td>\n",
       "      <td id=\"T_de4df_row1_col2\" class=\"data row1 col2\" >175863450273431951272574976.0000</td>\n",
       "      <td id=\"T_de4df_row1_col3\" class=\"data row1 col3\" >13059125030560.9121</td>\n",
       "      <td id=\"T_de4df_row1_col4\" class=\"data row1 col4\" >-28030436601603861143093248.0000</td>\n",
       "      <td id=\"T_de4df_row1_col5\" class=\"data row1 col5\" >16.0281</td>\n",
       "      <td id=\"T_de4df_row1_col6\" class=\"data row1 col6\" >314885123452.4015</td>\n",
       "      <td id=\"T_de4df_row1_col7\" class=\"data row1 col7\" >83.1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x73c2695b1710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ca871f8bb14abeb1287bfdaeac0da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup = pcr.setup(data=train,\n",
    "                  target='transformed_target',\n",
    "                  normalize=True,\n",
    "                  transformation=True,\n",
    "                  transform_target=False, \n",
    "                  date_features=['date'],\n",
    "                  session_id=123)\n",
    "\n",
    "# Comparaison des modèles\n",
    "best_models = pcr.compare_models(sort='RMSE')\n",
    "\n",
    "# Création d'un modèle de stacking (combinaison de plusieurs modèles)\n",
    "stacker = pcr.create_model('stack_models')\n",
    "\n",
    "# Tuning des hyperparamètres\n",
    "tuned_model = pcr.tune_model(stacker)\n",
    "\n",
    "# Validation finale\n",
    "eval_model = pcr.evaluate_model(tuned_model)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "predictions = pcr.predict_model(tuned_model, data=test)\n",
    "\n",
    "# Analyse des erreurs\n",
    "pcr.plot_model(tuned_model, plot='residuals')\n",
    "pcr.plot_model(tuned_model, plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pycaret.regression import *\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# # Vos transformateurs personnalisés\n",
    "# class MultiLabelBinarizerTransformer(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         self.mlbs = {}  # Stocke un MultiLabelBinarizer pour chaque colonne\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         for col in X.columns:\n",
    "#             self.mlbs[col] = MultiLabelBinarizer()\n",
    "#             self.mlbs[col].fit(X[col])\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         transformed_list = []\n",
    "#         for col in X.columns:\n",
    "#             transformed = self.mlbs[col].transform(X[col])\n",
    "#             new_columns = [f\"{col}_{label}\" for label in self.mlbs[col].classes_]\n",
    "#             transformed_list.append(pd.DataFrame(transformed, columns=new_columns, index=X.index))\n",
    "#         return pd.concat(transformed_list, axis=1)\n",
    "    \n",
    "#     def get_feature_names_out(self, input_features=None):\n",
    "#         # Collecter tous les noms de colonnes de sortie\n",
    "#         feature_names = []\n",
    "#         for col in self.mlbs.keys():\n",
    "#             feature_names.extend([f\"{col}_{label}\" for label in self.mlbs[col].classes_])\n",
    "#         return np.array(feature_names)\n",
    "\n",
    "# class CustomDateTransformer(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         self.feature_names_out = ['year', 'month', 'day', 'dayofweek']\n",
    "        \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "        \n",
    "#     def transform(self, X):\n",
    "#         # Assumant que X est un DataFrame avec une colonne 'date'\n",
    "#         result = pd.DataFrame({\n",
    "#             'year': X.dt.year,\n",
    "#             'month': X.dt.month,\n",
    "#             'day': X.dt.day,\n",
    "#             'dayofweek': X.dt.dayofweek\n",
    "#         })\n",
    "#         return result\n",
    "    \n",
    "#     def get_feature_names_out(self, input_features=None):\n",
    "#         return np.array(self.feature_names_out)\n",
    "\n",
    "# # Fonction pour préparer les données et les transformer avec vos transformateurs personnalisés\n",
    "# def prepare_data_for_pycaret(df, list_categorical_features=None):\n",
    "#     \"\"\"\n",
    "#     Prépare les données en appliquant les transformateurs personnalisés\n",
    "#     avant de les passer à PyCaret\n",
    "    \n",
    "#     Args:\n",
    "#         df: DataFrame à transformer\n",
    "#         list_categorical_features: Liste des colonnes contenant des listes de catégories\n",
    "    \n",
    "#     Returns:\n",
    "#         DataFrame transformé\n",
    "#     \"\"\"\n",
    "#     df_copy = df.copy()\n",
    "    \n",
    "#     # Appliquer le transformateur de date si une colonne 'date' existe\n",
    "#     if 'date' in df_copy.columns:\n",
    "#         date_transformer = CustomDateTransformer()\n",
    "#         date_features = date_transformer.transform(df_copy['date'])\n",
    "        \n",
    "#         # Supprimer la colonne date originale et ajouter les nouvelles colonnes\n",
    "#         df_copy = df_copy.drop('date', axis=1)\n",
    "#         df_copy = pd.concat([df_copy, date_features], axis=1)\n",
    "    \n",
    "#     # Appliquer le MultiLabelBinarizer pour les colonnes de listes catégorielles\n",
    "#     if list_categorical_features:\n",
    "#         list_transformer = MultiLabelBinarizerTransformer()\n",
    "#         list_features_df = list_transformer.fit_transform(df_copy[list_categorical_features])\n",
    "        \n",
    "#         # Supprimer les colonnes originales et ajouter les nouvelles colonnes\n",
    "#         df_copy = df_copy.drop(list_categorical_features, axis=1)\n",
    "#         df_copy = pd.concat([df_copy, list_features_df], axis=1)\n",
    "    \n",
    "#     return df_copy\n",
    "\n",
    "# # Exemple d'utilisation avec PyCaret\n",
    "# def run_pycaret_regression(data, target_column, list_categorical_features=None):\n",
    "#     \"\"\"\n",
    "#     Configuration et exécution d'un modèle de régression avec PyCaret\n",
    "    \n",
    "#     Args:\n",
    "#         data: DataFrame avec toutes les colonnes\n",
    "#         target_column: Nom de la colonne cible\n",
    "#         list_categorical_features: Liste des colonnes contenant des listes de catégories\n",
    "#     \"\"\"\n",
    "#     # Préparer les données\n",
    "#     prepared_data = prepare_data_for_pycaret(data, list_categorical_features)\n",
    "    \n",
    "#     # Initialiser l'environnement PyCaret avec un ensemble réduit de paramètres\n",
    "#     s = setup(\n",
    "#         data=prepared_data,\n",
    "#         target=target_column,\n",
    "#         session_id=42,\n",
    "#         normalize=True,           # Normalisation des variables numériques\n",
    "#         transformation=True,      # Transformations automatiques pour la correction de la skewness\n",
    "#         ignore_features=None,     # Colonnes à ignorer\n",
    "#         categorical_features=None, # Colonnes catégorielles standards\n",
    "#         numeric_features=None,    # Colonnes numériques\n",
    "#         date_features=None,       # Colonnes de date (déjà transformées)\n",
    "#         imputation_type='simple', # Méthode d'imputation\n",
    "#         numeric_imputation='median', # Valeur pour l'imputation des valeurs numériques\n",
    "#         categorical_imputation='mode', # Valeur pour l'imputation des valeurs catégorielles\n",
    "#         remove_multicollinearity=True, # Supprimer la multicolinéarité\n",
    "#         multicollinearity_threshold=0.9, # Seuil de multicolinéarité\n",
    "#         n_jobs=-1,               # Nombre de processeurs à utiliser (-1 pour tous)\n",
    "#         verbose=True              # Afficher les détails\n",
    "#     )\n",
    "    \n",
    "#     # Comparer tous les modèles\n",
    "#     best_models = compare_models(\n",
    "#         sort='RMSE',              # Trier par RMSE\n",
    "#         n_select=3,               # Sélectionner les 3 meilleurs modèles\n",
    "#         fold=5                    # 5-fold cross-validation\n",
    "#     )\n",
    "    \n",
    "#     # Afficher le meilleur modèle\n",
    "#     print(\"\\nMeilleur modèle:\")\n",
    "#     print(best_models[0])\n",
    "    \n",
    "#     # Créer un modèle d'ensemble avec les meilleurs modèles\n",
    "#     ensemble_model = ensemble_model(best_models)\n",
    "    \n",
    "#     # Évaluer le modèle d'ensemble\n",
    "#     evaluation = evaluate_model(ensemble_model)\n",
    "    \n",
    "#     # Affiner le meilleur modèle\n",
    "#     tuned_model = tune_model(\n",
    "#         best_models[0],\n",
    "#         optimize='RMSE',\n",
    "#         n_iter=50\n",
    "#     )\n",
    "    \n",
    "#     # Évaluer le modèle optimisé\n",
    "#     tuned_evaluation = evaluate_model(tuned_model)\n",
    "    \n",
    "#     # Retourner les modèles\n",
    "#     return {\n",
    "#         'setup': s,\n",
    "#         'best_models': best_models,\n",
    "#         'ensemble_model': ensemble_model,\n",
    "#         'tuned_model': tuned_model\n",
    "#     }\n",
    "\n",
    "# # Pour déployer le modèle final\n",
    "# def finalize_pycaret_model(models_dict, X_train, y_train, X_test=None, y_test=None):\n",
    "#     \"\"\"\n",
    "#     Finalise le modèle PyCaret avec les meilleures performances\n",
    "#     \"\"\"\n",
    "#     # Finaliser le modèle (entraînement sur l'ensemble complet)\n",
    "#     final_model = finalize_model(models_dict['tuned_model'])\n",
    "    \n",
    "#     # Sauvegarder le pipeline complet\n",
    "#     save_model(final_model, 'final_pycaret_model')\n",
    "    \n",
    "#     # Prédictions sur les données de test si disponibles\n",
    "#     if X_test is not None and y_test is not None:\n",
    "#         predictions = predict_model(final_model, data=X_test)\n",
    "#         print(\"Performance sur les données de test:\")\n",
    "#         print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, predictions['prediction']))}\")\n",
    "    \n",
    "#     return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = X_train.copy()\n",
    "# train_data[target] = y_train\n",
    "\n",
    "# models = run_pycaret_regression(\n",
    "#     data=train_data,\n",
    "#     target_column=target,\n",
    "#     list_categorical_features=list_categorical_features\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = finalize_pycaret_model(\n",
    "#     models_dict=models,\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
